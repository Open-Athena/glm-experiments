_target_: glm_experiments.data.lm_datamodule.MLMDataModule

# Dataset and tokenizer (override in specific configs)
dataset_name: data/gpn-animal-promoter-dataset
tokenizer_name: gonzalobenegas/tokenizer-dna-mlm

# Batch size configuration
batch_size: 32 # Total effective batch size (for gradient accumulation calculation)
per_device_batch_size: 32 # Batch size per device (what fits in GPU memory)
num_workers: 4
pin_memory: true

# Soft masking for genomic soft-masked regions (lowercase nucleotides)
soft_masked_weight: 0.01 # Loss weight for soft-masked regions in main training loss

# Data augmentation
data_augmentation: true # Reverse complement augmentation (training only)

# Validation dataset size (LM only, not TraitGym)
max_val_lm_samples: null # Maximum number of samples for LM validation (null = unlimited)

# Reproducibility
seed: 42

# Evaluation datasets (optional)
# Set evals: null to disable all evals, or configure specific evals below
evals:
  traitgym_mendelian_promoter:
    dataset_name: songlab/TraitGym
    dataset_config: mendelian_traits
    genome_url: https://ftp.ensembl.org/pub/release-115/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna_sm.toplevel.fa.gz
    genome_path: data/Homo_sapiens.GRCh38.dna_sm.toplevel.fa.gz
    window_size: 512
    batch_size: 128
