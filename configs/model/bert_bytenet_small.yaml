_target_: glm_experiments.models.bert_lit_module.BERTLitModule

net:
  _target_: glm_experiments.models.components.bert.BERT
  embedder:
    _target_: torch.nn.Embedding
    num_embeddings: 7
    embedding_dim: 128
    padding_idx: 0
  encoder:
    _target_: glm_experiments.models.components.bytenet.ByteNet
    hidden_size: ${..embedder.embedding_dim}
    n_layers: 8 # Smaller for debug
    slim: true
    dilation_base: 2
    dilation_cycle: 8
    first_kernel_size: 9
    rest_kernel_size: 5
  decoder:
    _target_: torch.nn.Linear
    in_features: ${..embedder.embedding_dim}
    out_features: ${..embedder.num_embeddings}

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.001
  weight_decay: 0.01

scheduler:
  _target_: transformers.get_constant_schedule_with_warmup
  _partial_: true
  num_warmup_steps: 100

compile: True
